import { ChangeDetectionStrategy, Component, inject, input, signal } from '@angular/core';
import { toObservable, toSignal } from '@angular/core/rxjs-interop';
import { filter, switchMap } from 'rxjs';
import { FirebaseService } from '../ai/services/firebase.service';
import { AudioTranscriberComponent } from '../audio-transcriber/audio-transcriber.component';
import { StoryGeneratorComponent } from '../story-generator/story-generator.component';
import { SelectedAudio } from '../types';

@Component({
  selector: 'app-audio-story',
  imports: [
    AudioTranscriberComponent,
    StoryGeneratorComponent,
  ],
  template: `
    @if (selectedClip(); as selectedClip) {
        <app-audio-transcriber [audioBlob]="selectedClip" (topicTranscribed)="handleTopicTranscribed($event)" />
        <div class="px-6 py-2 bg-slate-800 text-white rounded-lg shadow-xl w-full mx-auto">
          @if (loadingImage(); as loading) {
            <p class="flex items-center justify-center">
              <svg class="animate-spin -ml-1 mr-3 h-5 w-5 text-white" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
              </svg>
                Loading image...
            </p>
          }
          @if (!loadingImage()) {
            @if (base64ImageData(); as imageData) {
              <p class="text-lg font-semibold mb-2 text-sky-300">
                Image generated by Firebase AI Logic:
              </p>
              <img [src]="imageData" [alt]="transcribedTopic()"  width="400" height="400" />
            
            }
          }
        </div>
        <app-story-generator [topic]="transcribedTopic()" />
    }
  `,
  changeDetection: ChangeDetectionStrategy.OnPush,
})
export class AudioStoryComponent {
    selectedClip = input<SelectedAudio | undefined>(undefined);
    transcribedTopic = signal('');

    firebaseService = inject(FirebaseService);

    loadingImage = signal(false);
    base64ImageData = toSignal(toObservable(this.transcribedTopic)
      .pipe(
        filter((topic) => !!topic),
        switchMap((topic) =>  {
          this.loadingImage.set(true);
          return this.firebaseService.generateImage(topic)
            .then((imageData) => {
              const mimeType = imageData.mimeType;
              const base64Data = imageData.bytesBase64Encoded;
              return `data:${mimeType};base64,${base64Data}`;
            })
            .catch((err) => { 
              console.log(err);
              return '';
            })
            .finally(() => this.loadingImage.set(false))
        })
      ), { initialValue: ''});

    handleTopicTranscribed(topic: string): void {
        this.transcribedTopic.set(topic);

        if (topic) {
          this.firebaseService.generateImage(topic)
            .then((imageData) => console.log(imageData))
            .catch((err) => console.log(err));
        }
    }
}
